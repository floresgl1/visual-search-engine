# visual-search-engine
smart visual search engine using RAG and computer vision
<<<<<<< HEAD
=======

>>>>>>> 6345e96 (initial project setup with structure and dependencies)
# Visual Search Engine

A smart visual search engine that allows you to search through image collections using natural language queries. Built with PyTorch, TensorFlow, OpenCV, and RAG (Retrieval-Augmented Generation).

## ğŸ¯ Project Overview

This project demonstrates:
- **Computer Vision**: Image preprocessing and feature extraction
- **RAG**: Vector database storage and semantic search
- **Deep Learning**: CLIP model for image-text embeddings
- **MLOps**: Docker containerization and deployment

## ğŸ› ï¸ Tech Stack

- **PyTorch**: Primary framework for CLIP model
- **TensorFlow**: Alternative implementation
- **OpenCV**: Image preprocessing
- **ChromaDB/FAISS**: Vector database for RAG
- **Docker**: Containerization
- **FastAPI**: REST API backend
- **Google Colab**: Model training and experimentation

## ğŸ“ Project Structure

```
visual-search-engine/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original images
â”‚   â”œâ”€â”€ processed/        # Preprocessed images
â”‚   â””â”€â”€ embeddings/       # Stored embeddings
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_embedding_generation.ipynb
â”‚   â”œâ”€â”€ 03_retrieval_experiments.ipynb
â”‚   â””â”€â”€ 04_model_comparison.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ image_processor.py
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ pytorch_embedder.py
â”‚   â”‚   â””â”€â”€ tensorflow_embedder.py
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â””â”€â”€ vector_db.py
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ app.py
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Git
- Docker (optional)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/YOUR_USERNAME/visual-search-engine.git
cd visual-search-engine
```

2. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download sample dataset (instructions in notebooks)

### Usage

1. **Data Preparation**: Run `notebooks/01_data_exploration.ipynb`
2. **Generate Embeddings**: Run `notebooks/02_embedding_generation.ipynb`
3. **Test Search**: Run `notebooks/03_retrieval_experiments.ipynb`
4. **Start API**: `python src/api/app.py`

## ğŸ“Š Datasets

- MS COCO (330K images with captions)
- Flickr30k (31K images with descriptions)
- Unsplash Lite (25K+ high-quality photos)

## ğŸ” Example Queries

- "red car at sunset"
- "person walking dog in park"
- "modern architecture with glass"
- "beach with palm trees"

## ğŸ“ˆ Project Roadmap

- [x] Phase 1: Setup and data preparation
- [ ] Phase 2: PyTorch embedding generation
- [ ] Phase 3: RAG implementation
- [ ] Phase 4: TensorFlow alternative
- [ ] Phase 5: API development
- [ ] Phase 6: Dockerization
- [ ] Phase 7: Deployment

## ğŸ¤ Contributing

Contributions welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI CLIP model
- MS COCO dataset
- ChromaDB team
